# random variables
dist = scipy.stats. // Generate RNG
  randint(low, high)
  norm(loc, scale)
  bernoulli,binom,gamma}()
  uniform(loc, scale) // uniform [loc; loc + scale]
.rvs(size=n)  // draw n samples
.pdf(x)
.cdf(x)
.entropy()

# linalg
import scipy.linalg
solve(A, b)
eigvals, eigvecs = eig(A)
eigvals = eigvals(A)
svd(A)
cholesky(A)
LU(A)
norm(A, ord='fro')


# Sparse matrices
import scipy.sparse
efficient storage
fast matrix operations
## basics
lil_matrix  // list of lists; allows changes
csr_matrix  // compressed sparse row; constant
csc_matrix  // compressed sparse column; constant
coo_matrix  // coordinate form
s = X_matrix((nrow, ncol), dtype=)
s = X_matrix(np.array)  // from numpy array; 0 is interpreted as missing value
s[a != 10] = a[a != 10] // 10 is missing value
s.todense(...), s.toarray()  // return dense numpy array
  order={'C', 'F'} // column order
  out=array // write to array instead of creating new one
s.dot(s)  // sparse matrix operation
s.nnz, s.getnnz()  // number of stored (non zero) values
s.sorted_indices()  // indices of stored elements as sparse matrix

## lil_matrix: list of lists
+ fast modifications
- slow slicing
- slow operations
-> use for construction and convert to csr or csc afterwards

## csr_matrix: compressed sparse row
+ fast operations
+ fast row a[0, :] slicing
- slow modifications
- slow column splicing

## csc_matrix: compressed sparse column
+ fast column splicing

## coo_matrix: coordinate form
+ fast conversion to csr/csc
- no operations
- no slicing


# Optimization
import scipy.optimize
fmin_bfgs(fun, x0, fprime=fun_dev, ...)
  fun // function to be minimized
  x0  // starting point
  fprime  // derivative
  args  // arguments as tuple passed to fun and fun_dev
  disp=False  // suppress output
  full_output=True  // return [xmin, ymin, grad, ...]
brent(f)  // minimize scalar function
fminbound(f, x1, x2)  // minimize scalar function

# Interpolation
import scipy.interpolate
interp1d(x, y, kind='linear')
  kind='quadratic': spline^2
  kind='cubic': spline^3

# Convolution
scipy.signal.convolve(x, k, mode='full')
* convolution over x with kernel k

## full
* size: n + k - 1
k k k             k k k
    x x x  -> x x x
## same
* size: n
k k k         k k k
  x x x  -> x x x
## valid
* size: n - k + 1
k k k             k k k
x x x x x  -> x x x x x

## Other filters
import scipy.ndimage.filters
gaussian_filter(x, [size, size]) // convolve with size x size Gaussian kernel
gaussian_laplace(...)


# Correlation coefficient / correlation matrix / spearman
* Example below
* If y is None, computes correlations between columns of x

import scipy.stats as sps

x = np.random.rand(100)
y = np.random.rand(100)

r, pval = sps.spearmanr(x, y)
  * returns named collection with r and pval
r, pval = sps.pearsonr(x, y)
  * returns tuple with r and pval
